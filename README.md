


# Apache Spark Python Practice Project 

Welcome to my personal Apache Spark practice repository!

This project is a collection of hands-on examples and practice scripts created while I was learning **Apache Spark** using **PySpark**. It includes fundamental concepts like RDDs and DataFrames, working with structured and unstructured data, file formats, Spark SQL, joins, aggregations, window functions, and more.

---

## üåü About This Project

I created this repository as a personal playground to explore and practice different features of Apache Spark. Each file represents a step in my learning journey ‚Äî from basic operations to advanced transformations and queries using PySpark.

---

## üìÅ File Overview

| File Name                          | Description                                                                |
|-----------------------------------|----------------------------------------------------------------------------|
| `aggregate_in_spark.py`           | Practice on aggregation operations using DataFrames                        |
| `bucket_join_in_spark.py`         | Implementation of bucket joins in Spark                                    |
| `composer.py`                     | Modular composition of Spark tasks and operations                          |
| `dataproc_file.py`                | General data processing using Spark                                        |
| `first_simple_progarm.py`         | My first basic Spark script                                                |
| `grouping_with_aggrigate.py`      | GroupBy operations with aggregate functions                                |
| `join_in_spark.py`                | Performing different types of joins in Spark                               |
| `outer_join_spark.py`            | Working with outer joins                                                   |
| `rdd_api.py`                      | Exploring RDD operations like map, filter, reduce                          |
| `read_csv_file_spark_progarm.py`  | Reading CSV files using Spark DataFrame API                                |
| `read_jsonfile_in_spark.py`       | Reading and analyzing JSON files                                           |
| `README.md`                       | This README file                                                           |
| `shuffle_join_spark.py`          | Demonstration of shuffle join behavior                                     |
| `spark_parquet.py`                | Working with Parquet files in Spark                                        |
| `spark_temp_view.py`              | Creating and querying temporary views                                      |
| `task.py`                         | Custom Spark tasks for practice                                            |
| `test_unit1.py`                   | Unit tests for Spark job logic                                             |
| `test_unit2.py`                   | Additional unit tests                                                      |
| `unstructure_data.py`            | Handling unstructured data in Spark                                        |
| `window_function.py`              | Using window functions for advanced analytics                              |

---

## üéØ Learning Goals

- Understand Spark architecture and local setup
- Learn and differentiate between RDD and DataFrame APIs
- Perform file reads/writes (CSV, JSON, Parquet)
- Practice joins: inner, outer, shuffle, bucket joins
- Implement window functions and aggregations
- Use temporary views and Spark SQL
- Modularize and test Spark code

---

## üõ†Ô∏è How to Run

Install PySpark:

```bash
pip install pyspark
````

Run any script using:

```bash
spark-submit <filename>.py
```

Run unit tests:

```bash
pytest test_unit1.py
```

---

## üôã‚Äç‚ôÇÔ∏è Why I Created This

I'm learning Apache Spark, and this repository is a reflection of that journey. These scripts helped me understand real-world data processing using distributed computing and Python. I continuously improve this as I learn new concepts.

---

## üìå Note

This is a practice-based project ‚Äî not a production-ready codebase. It's built for learners, by a learner. Use it to understand Spark by trying, breaking, fixing, and experimenting.

---

If this helps you in your Spark learning journey, feel free to ‚≠ê this repo or connect with me on [LinkedIn](https://www.linkedin.com/in/alok-nath-tiwari/).

Happy learning! üíª‚ö°

‚Äî **Alok Nath Tiwari**
